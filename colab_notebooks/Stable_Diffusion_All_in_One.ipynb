{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMQuehl/stable-diffusion/blob/colab/colab_notebooks/Stable_Diffusion_All_in_One.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd-vX3cavOCt"
      },
      "source": [
        "# **Stable Diffusion** \n",
        "In order to use this colab, first get an access token for the stable diffusion weights hosted on huggingface (https://huggingface.co/CompVis/stable-diffusion). If you accepted the license for this model and generated a key, put that key into the access_token field below.\n",
        "\n",
        "If you get cuda_out_of_memory or similar errors, try using the lower precision model. There is an (optional) SFW filter, which you can enable below in order to ensure that no offensive content might be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDUi8tYoUEWZ"
      },
      "outputs": [],
      "source": [
        "access_token = \"put_your_token_here\" #@param{type: 'string'}\n",
        "if not access_token.startswith(\"hf_\"):\n",
        "  from huggingface_hub import notebook_login\n",
        "  notebook_login()\n",
        "  access_token = True\n",
        "use_lower_precision = False #@param{type: 'boolean'}\n",
        "use_pipeline_with_safety_filter = False #@param{type: 'boolean'}\n",
        "#@markdown If you connect your Google Drive, you can save the final image of each run on your drive.\n",
        "use_google_drive = True #@param{type: 'boolean'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYOlvQ1nQL7c"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "First, please make sure you are using a GPU runtime to run this notebook, so inference is much faster. If the following command fails, use the `Runtime` menu above and select `Change runtime type`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHkHsdtnry57"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "if use_google_drive: \n",
        "  try:\n",
        "      from google.colab import drive\n",
        "      print(\"Google Colab detected. Using Google Drive.\")\n",
        "      is_colab = True\n",
        "      #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "      save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "  except:\n",
        "      is_colab = False\n",
        "      use_google_drive = False\n",
        "      save_models_to_google_drive = False\n",
        "      print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if use_google_drive :\n",
        "        drive.mount('/content/drive')\n",
        "        root_path = '/content/drive/MyDrive/AI/Stable_Diffusion'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "\n",
        "outDirPath = f'{root_path}/images_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if (use_google_drive and not save_models_to_google_drive) or not use_google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if use_google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{root_path}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)"
      ],
      "metadata": {
        "id": "qX3uI1WVTY_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paJt_cx5QgVz"
      },
      "source": [
        "Prepare and set up libraries for Stable Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIrgth7sqFML"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy gradio datasets tqdm\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/4674fdf807cdefd4db1758067c0207872d805f8c/examples/inference/image_to_image.py\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buFaskR-mqqL"
      },
      "source": [
        "Prepare Stable Diffusion Pipelines for Text2Image and Image2Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSKWBKFPArKS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from image_to_image import StableDiffusionImg2ImgPipeline, preprocess\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "stable_diff_model_folder = f'{model_path}/stable-diffusion-v1-4'\n",
        "\n",
        "if use_lower_precision:\n",
        "  hf_revision = \"fp16\"\n",
        "  torch_type = torch.float16\n",
        "else:\n",
        "  hf_revision = None\n",
        "  torch_type = None\n",
        "\n",
        "snapshot_download(repo_id=\"CompVis/stable-diffusion-v1-4\", cache_dir=stable_diff_model_folder, use_auth_token=access_token)\n",
        "print (\"Download completed.\")\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", cache_dir=stable_diff_model_folder, revision=hf_revision, torch_dtype=torch_type, use_auth_token=access_token) \n",
        "im2im_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", cache_dir=stable_diff_model_folder, revision=hf_revision, torch_dtype=torch_type, use_auth_token=access_token)\n",
        "\n",
        "if not use_pipeline_with_safety_filter:\n",
        "  def dummy_checker(images, **kwargs): return images, False\n",
        "  pipe.safety_checker = dummy_checker\n",
        "  im2im_pipe.safety_checker = dummy_checker\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "im2im_pipe = im2im_pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPT8PCT67TvA"
      },
      "source": [
        "Define Helper Function(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2YMlltn7V6J"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "def get_free_filename(folder, base_file_name, extension=\"png\"):\n",
        "  i = 0\n",
        "  i_string = str(i).rjust(4, \"0\")\n",
        "  while os.path.exists(os.path.join(folder, f\"{base_file_name}_{i_string}.{extension}\")):\n",
        "    i += 1\n",
        "    i_string = str(i).rjust(4, \"0\")\n",
        "  return f\"{base_file_name}_{i_string}\", os.path.join(folder, f\"{base_file_name}_{i_string}.{extension}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NXFFfjsS-zj"
      },
      "source": [
        "# 2. Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xQFDu7YcYH9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "#@markdown #####**General-Settings:**\n",
        "batch_name =\"Portals\" #@param{type: 'string'}\n",
        "prompt = \"A portal to the depths of hell, octane render, 4k\" #@param{type: 'string'}\n",
        "width = 512 #@param{type: 'number'}\n",
        "height = 512 #@param{type: 'number'}\n",
        "steps = 50 #@param{type: 'number'}\n",
        "use_seed = False #@param{type: 'boolean'}\n",
        "seed = 0 #@param{type: 'number'}\n",
        "guidance_scale = 7.5 #@param{type: 'number'}\n",
        "num_cols = 2 #@param{type: 'number'}\n",
        "num_rows = 2 #@param{type: 'number'}\n",
        "batch_size = num_rows * num_cols\n",
        "\n",
        "#@markdown #####**Init_Image-Settings:**\n",
        "use_init_image = False #@param{type: 'boolean'}\n",
        "init_image_strength = 0.9 #@param{type: 'number'}\n",
        "upload_new_image = False #@param{type: 'boolean'}\n",
        "#@markdown if a new image is uploaded that takes precedence over the batch image.\n",
        "use_image_from_previous_batch_as_init = True #@param{type: 'boolean'}\n",
        "batch_image_number = 0 #@param{type: 'number'}\n",
        "resize = False #@param{type: 'boolean'}\n",
        "\n",
        "file_extension = \"png\" #@param{type: 'string'}\n",
        "\n",
        "if height > 512 or width > 512:\n",
        "  print(\"Warning: If height or width are larger than 512 coherence might be lost!\")\n",
        "\n",
        "generator = torch.Generator(\"cuda\")\n",
        "\n",
        "if use_init_image :\n",
        "  if use_image_from_previous_batch_as_init and \"all_images\" in globals():\n",
        "    init_image = all_images[batch_image_number]\n",
        "\n",
        "  if not \"init_image\" in globals() or upload_new_image: \n",
        "    upload_folder = 'upload'\n",
        "    if os.path.isdir(upload_folder):\n",
        "        shutil.rmtree(upload_folder)\n",
        "    os.mkdir(upload_folder)\n",
        "    # upload images\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys() :\n",
        "      dst_path = os.path.join(upload_folder, filename)\n",
        "      print(f'move {filename} to {dst_path}')\n",
        "      shutil.move(filename, dst_path)\n",
        "    filename = os.path.join(upload_folder, list(uploaded.keys())[0])\n",
        "    init_image = Image.open(filename).convert(\"RGB\")\n",
        "\n",
        "\n",
        "  if (resize):\n",
        "    init_image = init_image.resize((width, height))\n",
        "  init_image_cuda = preprocess(init_image)\n",
        "  print (\"Init image will be: \")\n",
        "  display(init_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxpIxszve_wY"
      },
      "source": [
        "# 3. Run Standard Pipeline\n",
        "\n",
        "If using a seed this image will always be the same for the same *prompt*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEErJFjlrSWS"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "from torch import autocast\n",
        "\n",
        "if not use_seed :\n",
        "  import random\n",
        "  random.seed()\n",
        "  seed = random.randint(0, 2**32)\n",
        "\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "print(\"using seed: {seed}\".format(seed = seed))\n",
        "\n",
        "prompts = [prompt] * num_cols\n",
        "\n",
        "all_images = []\n",
        "for i in range(num_rows):\n",
        "  with autocast(\"cuda\"):\n",
        "    if not use_init_image or \"init_image_cuda\" not in globals():\n",
        "      images = pipe(prompts, num_inference_steps=steps, height=height, width=width, generator=generator, guidance_scale=guidance_scale)[\"sample\"]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
        "    else:\n",
        "      images = im2im_pipe(prompts, num_inference_steps=steps, generator=generator, guidance_scale=guidance_scale, init_image=init_image_cuda, strength=init_image_strength)[\"sample\"]\n",
        "  all_images.extend(images)\n",
        "\n",
        "grid = image_grid(all_images, rows=num_rows, cols=num_cols)\n",
        "grid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to save any images, run the following cell"
      ],
      "metadata": {
        "id": "4zyzfK7aarIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "only_save_image_with_number = 3 #@param{type: 'number'}\n",
        "save_all_images = False #@param{type: 'boolean'}\n",
        "\n",
        "out_batch_path = os.path.join(outDirPath, batch_name)\n",
        "createPath(out_batch_path)\n",
        "\n",
        "if not save_all_images and 0 <= only_save_image_with_number < len(all_images):\n",
        "  out_file_name, full_out_file_path = get_free_filename(out_batch_path, hash(prompt), file_extension)\n",
        "elif save_all_images:\n",
        "  for image in all_images:\n",
        "    out_file_name, full_out_file_path = get_free_filename(out_batch_path, hash(prompt), file_extension)\n",
        "    prompt_file = open(os.path.join(out_batch_path, str(hash(prompt)) + \"_prompt.txt\"), 'w')\n",
        "    prompt_file.write(prompt)\n",
        "    prompt_file.close()\n",
        "\n",
        "    print (f\"saving picture to : {full_out_file_path}\")\n",
        "    image.save(full_out_file_path)\n",
        "else:\n",
        "  print(\"saving no picture...\")"
      ],
      "metadata": {
        "id": "4n0I4e3map1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZq_q3XIe53"
      },
      "source": [
        "# 4. Prepare ESRGAN for upscaling an image\n",
        "Set Upscaler Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bHr_fQVHkkP"
      },
      "outputs": [],
      "source": [
        "image_to_enhance = 3 #@param{type: 'number'}\n",
        "pil_img = all_images[image_to_enhance]\n",
        "\n",
        "esrgan_model_name = \"RealESRGAN_x4plus\" #@param [\"RealESRGAN_x4plus\", \"RealESRNet_x4plus\", \"RealESRGAN_x4plus_anime_6B\", \"RealESRGAN_x2plus\", \"realesr-animevideov3\"]\n",
        "outscale = 2 #@param{type: 'number'}\n",
        "face_enhance = True #@param{type: 'boolean'}\n",
        "\n",
        "esrgan_out_batch_path = os.path.join(outDirPath, f\"{batch_name}_ESRGAN\")\n",
        "createPath(esrgan_out_batch_path)\n",
        "\n",
        "out_file_name, full_out_file_path = get_free_filename(esrgan_out_batch_path, hash(prompt), file_extension)\n",
        "prompt_file = open(os.path.join(esrgan_out_batch_path, str(hash(prompt)) + \"_prompt.txt\"), 'w')\n",
        "prompt_file.write(prompt)\n",
        "prompt_file.close()\n",
        "\n",
        "print (f\"saving picture to : {full_out_file_path}\")\n",
        "\n",
        "all_images[image_to_enhance].save(full_out_file_path)\n",
        "all_images[image_to_enhance]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv1dIt_zImeP"
      },
      "outputs": [],
      "source": [
        "if not \"esrgan_initialized\" in globals():\n",
        "  # Clone Real-ESRGAN and enter the Real-ESRGAN\n",
        "  !git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "  %cd Real-ESRGAN\n",
        "  # Set up the environment\n",
        "  !pip install basicsr\n",
        "  !pip install facexlib\n",
        "  !pip install gfpgan\n",
        "  !pip install -r Real-ESRGAN/requirements.txt\n",
        "  !python setup.py develop\n",
        "  # Download the pre-trained model  \n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P '{model_path}/ESRGAN_models' -nc\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/RealESRNet_x4plus.pth -P '{model_path}/ESRGAN_models' -nc\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P '{model_path}/ESRGAN_models' -nc\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth -P '{model_path}/ESRGAN_models' -nc\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth -P '{model_path}/ESRGAN_models' -nc\n",
        "  !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P '{model_path}/ESRGAN_models' -nc\n",
        "  !cp {model_path}/ESRGAN_models/* 'experiments/pretrained_models'\n",
        "\n",
        "  esrgan_initialized = True\n",
        "  %cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "%cd Real-ESRGAN\n",
        "if face_enhance:\n",
        "  !python inference_realesrgan.py -n RealESRGAN_x4plus -i {full_out_file_path} --outscale {outscale} -o {esrgan_out_batch_path} --face_enhance\n",
        "else:\n",
        "  !python inference_realesrgan.py -n RealESRGAN_x4plus -i {full_out_file_path} --outscale {outscale} -o {esrgan_out_batch_path}\n",
        "%cd ..\n",
        "\n",
        "shutil.move(os.path.join(esrgan_out_batch_path, f\"{out_file_name}_out.{file_extension}\"), os.path.join(esrgan_out_batch_path, f\"{out_file_name}_upscaled.{file_extension}\"))\n",
        "upscaled_image = Image.open(os.path.join(esrgan_out_batch_path, f\"{out_file_name}_upscaled.{file_extension}\"))\n",
        "upscaled_image"
      ],
      "metadata": {
        "id": "qxQxpf0wr9Ba"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Stable Diffusion - All in One",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}